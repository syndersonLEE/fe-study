# Ch3. OS Cache and Distribution

### lecture 8

#### OS 캐시 구조

##### 페이지 캐시

- 디스크와 메모리 간 속도 차는 10^5 ~ 10^6배 이상
- 메모리를 통한 디스크 엑세스 줄이기
- Linux는 page cache, file cache, buffer cache 라는 캐시 구조를 갖추고 있음

#### Linux(x86)의 구조

- 선형 어드레스 -> 페이징 구조 -> 물리 어드레스 구조
    - 가상 메모리 구조 : 논리적인 선형 어드레스 -> 물리적 어드레스 변환
    - 스왑 : 물리 메모리가 부족할 때, 디스크를 메모리로 취급하여 해소

#### 가상 메모리 구조

- OS에서 메모리 관리
    1. 프로세스에서 메모리 요청
    2. OS에서 메모리 확인하여
    3. 비어 있는 어드레스 반환
- 이 과정에서 OS는 비어있는 메모리 정보를 관리해야 함
- 프로세스는 순차적으로 메모리 주소를 관리하는게 편함
- OS는 이를 위해서 실제 메모리 값과 가상 메모리 값을 치환해주는 매핑을 진행
- 디스크의 경우 4KB를 블록으로 확보하여 프로세스로 넘김 : 페이지라고 부름

#### Linux의 페이지 캐시 원리

1. 디스크의 정보를 메모리에 기입
2. 프로세스에 메모리 주소 정보를 OS가 알려줌
3. 프로세스가 메모리 정보에 접근
4. 커널이 메모리를 해제하지 않고 남겨둠

-> 이는 2회차 조회시 훨씬 빨라짐을 알 수 있음 : 윈도우나 리눅스 재부팅 시 느려지는 이유

#### VFS

- 파일 시스템 위에는 VFS라는 추상화 레이어가 존재
- VFS는 페이지 캐시의 구조를 지니고 있다

#### Linux는 페이지 단위로 디스크 캐싱

- 오버 캐싱이 가능한 이유?
    - 파일 1개 단위의 캐싱이 아닌 4KB 블록만을 캐싱
    - ex) 4KB 블록 = 페이지

##### LRU

- 가장 오래된 것을 파기하고 새로운 것을 남겨 놓는 형태

##### 캐싱 원리

- 리눅스는 i 노드라는 번호 & 파일 위치에서 어느 위치부터 시작할지 나타내는 오프셋
    - 위 두가지 정보로 캐싱 : 파일 일부 캐싱 가능
- 내부 구조는 Radix Tree로 아무리 커지더라도 캐시 탐색속도가 떨어지지 않음
    - 커다란 파일의 일부분을 캐싱 혹은 작은 파일을 캐싱해도 동일한 속도로 캐시 찾기 가능

#### 메모리가 비어있으면 캐싱

- 메모리가 남아있지 않다면, 오래된 캐시를 버리고 프로세스에 메모리 확보
- ex) sar -r 실행 시
    -  리눅스는 메모리가 비어있는 곳에 전부 캐싱을 진행

#### 메모리를 늘려서 I/O 부하 줄이기

- iowait 옵션을 통해 i/o부하 확인 가능 -> 항상 대기를 뜻함
- 메모리를 늘려서 줄이기 가능
- 하지만 이는 만능이 아님

#### 페이지 캐시는 투과적으로 작용

- 갑자기 매우 큰 파일을 캐싱할 경우 메모리 사용량이 크게 증가

#### sar 명령으로 OS 지표 참고하기

- sar
    - 두 가지 옵션 존재
        - 과거 통계 데이터 옵션 조회
        - 현재 데이터 주기적 확인

```
sar -f /var/log/sa/sa04 | head :  디렉터리에 저장된 과거 로그 정보
sar 1 3 : 1초 간격으로 3회
sar -u : CPU 사용률 확인
    - user : 사용자 모드에서 CPU가 소비된 비율
    - nice : 사용자 모드에서 CPU를 소비한 시간
    - system : 시스템 모드에서 CPU가 소비된 시간 비율
    - iowait : iowait을 위해 Idle 상태로 소비한 비율
    - steal : Xen 등 OS 가상화를 이용하고 있을 경우, 다른 가상 CPU의 계산으로 대기된 시간의 비율
    - idle : CPU가 디스크 I/O 대기없이 Idle로 소비된 비율
```

### Lecture 9

#### 캐시를 전제로 I/O 비율을 줄이는 방법

1. 데이터 규모에 비해 메모리가 크면 전부 캐싱 가능
    - 따라 데이터 규모가 중요
    - LZ 캐싱의 경우에도 2배이상 텍스트 축소
2. 경제적 비용과 밸런스를 통해 고민

#### 복수 서버로 확장

- 캐시서버로 해결 될 수 없는 구조의 경우
- AP 서버를 늘리는 경우 - CPU 부하를 낮추고 분산하기 위해
- DB 서버를 늘리는 경우 - 캐시 용량을 늘리고 효율을 높히기 위해

#### 단순한 대수 증설은 무의미

- 캐싱 불가 비율은 그대로 -> 다시 병목 발생

#### 페이지 캐시 

- 리눅스는 남아있는 메모리를 페이지 캐시로 활용하려고 함
    - 디스크로 부터 데이터 읽기
    - 페이지 캐시에 없을 경우
    - 메모리에 남아있을 경우
    - 새로운 캐시 생성

#### 페이지 캐시에 의한 I/O Bound 경감 효과

- 16GB로 늘렸을 경우 상당한 전송량 향상을 기대할 수 있음
- vmstat를 사용하면 실제 디스크 엑세스가 얼마나 증가하는 지 확인 가능

#### 페이지 캐시는 한 번의 read에서 시작

- 모든 DB 엑세스는 디스크 I/O를 발생
- I/O 바운드는 페이지 캐시 이전과 이후 속도가 다름

### Lecture 10

#### 국소성을 고려한 분산

- 엑세스 패턴을 고려한 분산
- 캐싱할 수 없는 부분이 사라진다

#### 파티셔닝

- 테이블 단위로 파티셔닝
- 테이블 하나를 여러 개의 작은 테이블로 분할 가능
- 추후 병합하는 이슈만 제외한다면, 구현 상 간단

#### 요청 패턴을 섬으로 분할

- 사용자의 특성이나 용도에 따라 시스템을 섬으로 나누는 방법

#### 페이지 캐시를 고려한 운용의 기본 규칙

- 따라서 OS 가동 직후 서버를 바로 투입하면 문제가 발생

1. 자주 사용하는 DB 파일 cat 선행
2. 로드밸런서 편입

#### 부하 분산과 OS의 기본 원리

- OS 캐시
- 멀티 스레드 및 멀티 프로세스
- 가상 메모리 구조
- 파일 시스템

위를 알아야 명확한 확인 가능
